{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0706_복습.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP5Uh4+ugmiPqMFDeY3Le/B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rumcrush/cakd3/blob/main/0706_%EB%B3%B5%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlEpogViaqA7"
      },
      "source": [
        "#원하는 웹사이트를 requests 모듈과 urllib모듈로 가져와서 text로 출력\n",
        "import requests\n",
        "response = requests.get('https://perfume-global.com/')\n",
        "\n",
        "print(response.status_code)\n",
        "print(response.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsgvLtXma-A3"
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "a = urllib.request.urlopen(\"https://perfume-global.com/\")\n",
        "print(a.read().decode(\"utf-8\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8u7YSJWa_GN"
      },
      "source": [
        "import requests\n",
        "URL = 'https://perfume-global.com/'\n",
        "response = requests.get(URL)\n",
        "content = response.text\n",
        "body = re.search('あ～ちゃん',content)\n",
        "print(body.group())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94LF3dg_a_zj"
      },
      "source": [
        "import requests\n",
        "URL = 'https://perfume-global.com/'\n",
        "response = requests.get(URL)\n",
        "content = response.text\n",
        "body = re.search('概要',content)\n",
        "print(body.group())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l12gH2NqbBQ2"
      },
      "source": [
        "import requests\n",
        "URL = 'https://perfume-global.com/'\n",
        "response = requests.get(URL)\n",
        "content = response.text\n",
        "body = re.search('Perfume',content)\n",
        "print(body.group())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su3qh-ymbBXq"
      },
      "source": [
        "#웹에서 이미지를 다운받아 저장하기 (가능한 이미지 선택)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyblhEqkbBbR"
      },
      "source": [
        "import urllib.request\n",
        "img_src = 'https://storage.perfume-global.com/lab/wp-content/uploads/2018/08/103_0.png'\n",
        "new_name = 'reframe.png'\n",
        "urllib.request.urlretrieve(img_src,new_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyQy2YAZbBes"
      },
      "source": [
        "#홈페이지를 로컬에 파일로 저장 \n",
        "import urllib\n",
        "request = urllib.request.Request('https://www.naver.com')\n",
        "data = urllib.request.urlopen(request).read()\n",
        "f = open('pc.html','wb')\n",
        "f.write(data)\n",
        "f.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHbq8_X-bBhz"
      },
      "source": [
        "with open('pc.html','rb') as f:\n",
        "    data = f.read().decode('utf-8')\n",
        "    print(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxUeBUoKbBlL"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "html = \"\"\"\n",
        "<html>\n",
        "<head>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>스크래핑이란?</h1>\n",
        "    <p>웹페이지를 분석하는 것</p> #문단을 나타냄\n",
        "    <p>원하는 부분을 추출하는 것</p> \n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "print(soup)\n",
        "\n",
        "print(h1)\n",
        "h1 = soup.body.h1\n",
        "print(h1.string)\n",
        "print(h1.text)\n",
        "\n",
        "p1 = soup.body.p\n",
        "\n",
        "p2 = p1.next_sibling.next_sibling\n",
        "print(p1.string)\n",
        "print(p1.text)\n",
        "print(p2.string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBDQybWgbBor"
      },
      "source": [
        "#### Butiful Soup 함수\n",
        "1. find () :HTML 태그에 대한 첫번째 정보를 가져옴 \n",
        "- find(속성=값) : HTML 해당 속성과 일치하는 값에 대한 첫번째 정보를 가져옴 \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhPK83GSbBsM"
      },
      "source": [
        "#ID로 요소를 찾는 방법 \n",
        "\n",
        "from bs4 import BeautifulSoup \n",
        "html = \"\"\"\n",
        "<body>\n",
        "    <h1 id='title'>스크래핑이란?</h1> #h1에 아이디 넣음\n",
        "    <p id='body'>웹페이지를 분석하는 것</p> #문단을 나타냄\n",
        "    <p>원하는 부분을 추출하는 것</p> \n",
        "</body>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html,'html.parser')\n",
        "title = soup.find(id='title')\n",
        "body = soup.find(id='body')\n",
        "\n",
        "\n",
        "print(title.string)\n",
        "print(body.string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNVzlGaSbBvn"
      },
      "source": [
        "#여러개의 요소 추출 \n",
        "html = \"\"\"\n",
        "<html><body>\n",
        "    <ul>\n",
        "        <li><a href=\"http://www.naver.com\">naver</a></li>\n",
        "        <li><a href=\"http://www.daum.net\">daum</a></li>\n",
        "    </ul>\n",
        "</body></html>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html,'html.parser')\n",
        "links = soup.find_all('a')\n",
        "\n",
        "for a in links:\n",
        "    href = a.attrs['href']\n",
        "    text = a.string\n",
        "    print(text, \">\", href)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpqRXDyzbBy5"
      },
      "source": [
        "html = \"\"\"\n",
        "<html><body>\n",
        "    <ul>\n",
        "        <li><a href=\"https://www.instagram.com/prfm_official/\">staff</a><li>\n",
        "        <li><a href=\"https://twitter.com/Perfume_Staff\"></a><li>\n",
        "    <ul>\n",
        "</body></html>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html,'html.parser')\n",
        "links = soup.find_all('a')\n",
        "\n",
        "for a in links:\n",
        "    href = a.attrs['href']\n",
        "    print(href)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqqM4nUXbB2O"
      },
      "source": [
        "import urllib\n",
        "from bs4 import BeautifulSoup as bs\n",
        "URL = 'http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp'\n",
        "response = urllib.request.Request(URL)\n",
        "text = urllib.request.urlopen(response).read()\n",
        "soup = bs(text,'html.parser')\n",
        "title = soup.find('title')\n",
        "wf = soup.find('wf')\n",
        "print(title.string)\n",
        "print(wf.string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPvNyDADbB5x"
      },
      "source": [
        "import urllib\n",
        "from bs4 import BeautifulSoup as bs\n",
        "URL = 'http://www.weather.go.kr/weather/forecast/mid-term-rss3.jsp'\n",
        "response = urllib.request.Request(URL)\n",
        "text = urllib.request.urlopen(response).read()\n",
        "soup = bs(text,'html.parser')\n",
        "title = soup.find('title')\n",
        "wf = soup.find('wf')\n",
        "print(title.string)\n",
        "print(wf.string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kE_gIO0bB85"
      },
      "source": [
        "#title과 wf에 있는 가장 앞에 있는 문장 뽑기 \n",
        "import urllib\n",
        "import requests\n",
        "request = urllib.request.Request('http://www.weather.go.kr/weather/forecast/mid-term-rss3.jsp')\n",
        "data = urllib.request.urlopen(request).read().decode('utf-8')\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "x = BeautifulSoup(data, 'html.parser')\n",
        "title = x.find('title')\n",
        "wf = x.find('wf')\n",
        "print(title.string)\n",
        "print(wf.string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZw_rf0TbCAj"
      },
      "source": [
        "find_all():\n",
        "- html의 해당 태그에 대한 모든 정보를 리스트 형식으로 가져옴 \n",
        "- 너무 많아서 몇개만 지정 할 때 쓰는 옵션 : limit\n",
        "- CSS속성으로 필터링\n",
        "- 클래스 할 때는 언더바 필요 : (class_(생략가능)로 클래스를 직접 사용. 혹은 attrs에서 속성 = 값으로 필터링 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VKC-N3WbCDv"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "req = requests.get('https://www.naver.com')\n",
        "html = req.text\n",
        "# print(html)\n",
        "\n",
        "soup = BeautifulSoup(html,'html.parser')\n",
        "result = soup.find_all('a',class_='link_set')\n",
        "result \n",
        "result2 = soup.find_all('a',class_ = \"_2aeXMlrb\")\n",
        "result2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puGDDh5lbCHU"
      },
      "source": [
        "print(soup.title)\n",
        "print(soup.title.name)\n",
        "print(soup.title.string)\n",
        "print(soup.img)\n",
        "print(soup.img['alt']) #속성일 땐 [] 씀 \n",
        "print(soup.a)\n",
        "print(soup.a['href'])\n",
        "print(soup.a.string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbrPJRdNbCKs"
      },
      "source": [
        "print(soup.find_all('a',limit=2))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Niukh0iCbCOU"
      },
      "source": [
        "#인덱스로 가져오기\n",
        "print(soup.find_all('a')[0]) #a태그의 1번째 인덱스 가져오기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YmHLyqzbCR8"
      },
      "source": [
        "#아이디로 가져오기 \n",
        "print(soup.find_all('div', id='u_skip'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-SgPaiTbCVz"
      },
      "source": [
        "print(soup.find_all('span',class_='blind'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avZNxV2xbCZn"
      },
      "source": [
        "#속성에서 키 값이 blind인 것을 가져오기 #limit으로 개수지정 가능\n",
        "print(soup.find_all('span',attrs={'class' : 'blind'},limit=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3P4ZS9YbCdR"
      },
      "source": [
        "#정규표현식 같이 쓰기 \n",
        "\n",
        "import re\n",
        "print(soup.find_all(string='네이버'))\n",
        "print(soup.find_all(string=re.compile('네이버')))\n",
        "print(soup.find_all(string=re.compile('네이버'),limit=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cafrVw8bCgu"
      },
      "source": [
        "# id, class 이걸 css선택자 라고 함\n",
        "from bs4 import BeautifulSoup\n",
        "html = \"\"\"\n",
        "<html>\n",
        "<style>\n",
        "</style>\n",
        "<body>\n",
        "<div id = \"meigen\">\n",
        "    <h1>위키북스 도서</h1>\n",
        "    <ul class=\"items\">\n",
        "        <li>유니티 게임 이펙트 입문</li>\n",
        "        <li>스위프트로 시작하는 아이폰 앱 개발 교과서</li>\n",
        "        <li>모던 웹사이트 디자인의 정석</li>\n",
        "    </ul>\n",
        "</div>\n",
        "</body></html>\n",
        "\"\"\"\n",
        "soup = BeautifulSoup(html,'html.parser')\n",
        "h1 = soup.select_one('div#meigen > h1').string\n",
        "print(h1)\n",
        "\n",
        "li_list = soup.select('div#meigen > ul.items > li')\n",
        "\n",
        "for li in li_list:\n",
        "    print(li.string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E1QgCyXbCkH"
      },
      "source": [
        "import urllib.request as req\n",
        "from bs4 import BeautifulSoup as bs\n",
        "URL = 'https://finance.naver.com/marketindex/'\n",
        "res = req.urlopen(url)\n",
        "text = urllib.request.urlopen(response).read()\n",
        "soup = BeautifulSoup(html,'html.parser')\n",
        "value = soup.select_one('span.value')\n",
        "print('usd/krw = ',value.string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZn_ya8UcAvz"
      },
      "source": [
        "import urllib.requests as req\n",
        "from bs4 import BeautifulSoup as bs\n",
        "url = 'http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp'\n",
        "response = urllib.request.Request(URL)\n",
        "text = urllib.request.urlopen(response).read()\n",
        "soup = bs(text,'html.parser')\n",
        "title = soup.find('title')\n",
        "wf = soup.find('wf')\n",
        "print(title.string)\n",
        "print(wf.string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5ipYiYNcAzA"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "fp = open('fruits-vegetables.html', encoding='utf-8')\n",
        "soup = BeautifulSoup(fp, 'html.parser')\n",
        "print(soup)\n",
        "print(soup.select_one('ul#fr-list > li.yellow').string)\n",
        "print(soup.select_one('ul#fr-list > li.purple').string)\n",
        "print(soup.select_one('ul#ve-list > li.white').string)\n",
        "print(soup.select_one('ul#ve-list > li.black').string)\n",
        "\n",
        "li3 = soup.select_one('ul#ve-list > li.black')\n",
        "li4 = soup.select('ul#ve-list > li.black')\n",
        "\n",
        "print(li3.string)\n",
        "print((li4[1].string))\n",
        "\n",
        "li1 = soup1.select_one(\"ul#ve-list > li.white\")\n",
        "li2 = soup1.select(\"ul#ve-list > li.white\")\n",
        "\n",
        "print(li1.string)\n",
        "print(li2[1].string)\n",
        "\n",
        "# 아보카도 5번 \n",
        "\n",
        "print(soup.select('ul#ve-list > li.black')[1].string)\n",
        "print(soup.find_all('li',attrs={'class':'black','data-lo':'us'})[0].string)\n",
        "print(soup.find_all('li',class_='black')[1].string)\n",
        "print(soup.find(attrs={'class':'black','data-lo':'us'}).string)\n",
        "\n",
        "cond = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXDvgBYfcA2G"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "fp = open('fruits-vegetables.html',encoding='utf-8')\n",
        "soup1 = BeautifulSoup(fp,'html.parser')\n",
        "li1 = soup1.select_one(\"ul#ve-list > li.white\") #select_one 은 .string으로 문자열만 출력 가능 하다\n",
        "li2 = soup1.select(\"ul#ve-list > li.white\") #select는 리스트 형태로 출력 되어서 string이 적용 안된다\n",
        "\n",
        "print(li1)\n",
        "print(li2[1].string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGPJfB9qcA5V"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "html = \"\"\"\n",
        "<html>\n",
        "<style>\n",
        "</style>\n",
        "<body>\n",
        "<div id = \"meigen\">\n",
        "    <h1>위키북스 도서</h1>\n",
        "    <ul class=\"items\">\n",
        "        <li>유니티 게임 이펙트 입문</li>\n",
        "        <li>스위프트로 시작하는 아이폰 앱 개발 교과서</li>\n",
        "        <li>모던 웹사이트 디자인의 정석</li>\n",
        "    </ul>\n",
        "</div>\n",
        "</body></html>\n",
        "\"\"\"\n",
        "soup = BeautifulSoup(html,'html.parser')\n",
        "h1 = soup.select_one('div#meigen > h1').string\n",
        "print(h1)\n",
        "\n",
        "li_list = soup.select('div#meigen > ul.items > li')\n",
        "\n",
        "for li in li_list:\n",
        "    print(li.string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob442JSfcA8X"
      },
      "source": [
        "# 정규표현식과 BeautifulSoup를 이용하여 https가 포함된 url만 출력하세요 \n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import re \n",
        "\n",
        "\n",
        "html = \"\"\"\n",
        "<ul>\n",
        "    <li><a href=\"hoge.html\">hoge</li>\n",
        "    <li><a href=\"https://example.com/fuga\">fuga*</li>\n",
        "    <li><a href=\"https://example.com/foo\">foo*</li>\n",
        "    <li><a href=\"http://example.com/aaa\">aaa</li>\n",
        "</ul>\n",
        "\"\"\"\n",
        "\n",
        "p = re.compile('https://.+')\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "list_find = soup.find_all(href=re.compile('^https'))\n",
        "\n",
        "for find in list_find:\n",
        "    print(find['href'])\n",
        "\n",
        "\n",
        "# ^ 의 의미 \n",
        "#1. 시작 대괄호가 없는 ^https 는 https로 시작하는 것을 찾아라 라는 의미\n",
        "#2. Not으로 쓸 때는 대괄호 안에 글자를 넣어줘야힘 [^https]\n",
        "#find_all은 여러 줄을 읽는다"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYKSqfd4cA_c"
      },
      "source": [
        "import urllib\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "response = urllib.request.Request('https://www.naver.com')\n",
        "data = urllib.request.urlopen(response).read().decode('utf-8')\n",
        "soup = BeautifulSoup(data,'html.parser')\n",
        "soup.select_one('a')\n",
        "# soup.find_all(href=re.compile('^#newsstand'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Der5KcQvcBCe"
      },
      "source": [
        "#여러개의 요소 추출 \n",
        "html = \"\"\"\n",
        "<html><body>\n",
        "    <ul>\n",
        "        <li><a href=\"http://www.naver.com\">naver</a></li>\n",
        "        <li><a href=\"http://www.daum.net\">daum</a></li>\n",
        "    </ul>\n",
        "</body></html>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html,'html.parser')\n",
        "links = soup.find_all('a')\n",
        "\n",
        "for a in links:\n",
        "    href = a.attrs['href']\n",
        "    text = a.string\n",
        "    print(text, \">\", href)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "aZATYNyLcBFo",
        "outputId": "9f320f85-b0a5-44c9-dd95-022c54e8a5ff"
      },
      "source": [
        "print(soup.select_one('ul#fr-list > li.yellow').string)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ce4a88225342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ul#fr-list > li.yellow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'soup' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YhCCqUNcBIt"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "\n",
        "html = urllib.request.urlopen('https://movie.naver.com/movie/sdb/rank/rmovie.nhn')\n",
        "titles = soup.find_all('td','title')\n",
        "\n",
        "\n",
        "rank =1 \n",
        "\n",
        "for movie in titles:\n",
        "    print(str(rank)+ \"위 : \" + movie.find('a').text)\n",
        "    rank += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fUs0WERcBLq",
        "outputId": "8cabccf2-3f13-46c7-a136-c52d590d867e"
      },
      "source": [
        "!pip install lxml"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (4.2.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eVDkq86eY26",
        "outputId": "8e87c539-f156-4d7f-e398-6a8bcaa4c33e"
      },
      "source": [
        "!pip install bs4"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtTdQIZkcBOt"
      },
      "source": [
        "# Q. 네이버 영화 랭킹 가져와서 첫번째 영화제목을 출력하세요."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "wbeSKMgScBR2",
        "outputId": "9a8b5d33-a108-47eb-c5be-fb2db83de451"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "\n",
        "html = urllib.request.urlopen('https://movie.naver.com/movie/sdb/rank/rmovie.nhn')\n",
        "titles = soup.find_all('td','title')\n",
        "print(titles[0].find('a').string)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5a8bc857c56b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://movie.naver.com/movie/sdb/rank/rmovie.nhn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtitles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'td'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'soup' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6ZDSdH6ecFp"
      },
      "source": [
        "# Q. 네이버 영화 랭킹 가져와서 전체 영화제목을 출력하세요.\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "\n",
        "html = urllib.request.urlopen('https://movie.naver.com/movie/sdb/rank/rmovie.nhn')\n",
        "titles = soup.find_all('td','title')\n",
        "\n",
        "rank = 1\n",
        "\n",
        "for v in titles:\n",
        "    print(str(rank) + \"위 \" + v.find('a').string)\n",
        "    \n",
        "    rank += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-nRmv5KecIk"
      },
      "source": [
        "# Q.\"http://api.aoikujira.com/time/get.php\"으로 부터 아래와 같이 출력하세요.\n",
        "# 2020/08/02 08:06:45\n",
        "# b'2020/08/02 08:06:45'\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "from urllib import request\n",
        "\n",
        "url = \"http://api.aoikujira.com/time/get.php\"\n",
        "res = request.urlopen(url)\n",
        "data = res.read()\n",
        "\n",
        "new_data = data.replace(data,new_text)\n",
        "\n",
        "new_text = b'2020/08/02 08:06:45'\n",
        "print(new_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2jC3E97ecLl"
      },
      "source": [
        "# Q.\"http://naver.com\"에서 header의 요소들을 가져와서 for문으로 출력하세요₩"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvcvaDBDecOt"
      },
      "source": [
        "import requests as req\n",
        "\n",
        "url = \"http://naver.com\"\n",
        "\n",
        "result = req.get(url)\n",
        "\n",
        "for v in result.headers:\n",
        "    print(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYPh74IJecR2"
      },
      "source": [
        "# Q. 아래 html에서 다음을 출력하세요.\n",
        "[<p>파이썬 크롤러 책1</p>, <p>전문서적</p>, <p>정보 문화사</p>]\n",
        "[<p id = \"d\">정보 문화사</p>\n",
        "[<p>파이썬 크롤러 책1</p>, <p>전문서적</p>]\n",
        "\n",
        "\n",
        "html =\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <title>Title</title>\n",
        "</head>\n",
        "<body>\n",
        "    <p>파이썬 크롤러 책1</p>\n",
        "    <p>전문서적</p>\n",
        "    <p id='d'>정보 문화사</p>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTYl3yJuecVU"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html =\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <title>Title</title>\n",
        "</head>\n",
        "<body>\n",
        "    <p>파이썬 크롤러 책1</p>\n",
        "    <p>전문서적</p>\n",
        "    <p id='d'>정보 문화사</p>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "soup3 = BeautifulSoup(html,'html.parser')\n",
        "print(soup3)\n",
        "\n",
        "res = soup3.select_one(\"p\")\n",
        "res2 = res.next_sibling.next_sibling\n",
        "res3 = soup3.find('p', id='d')\n",
        "\n",
        "print(res.string)\n",
        "print(res2.string)\n",
        "print(res3.string)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNQ2F3ybecY1"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <title>Title</title>\n",
        "    <style>\n",
        "        #target1{\n",
        "            font-size: 40px;\n",
        "            color: blue;\n",
        "        }\n",
        "        #target2{\n",
        "            font-size: 40px;\n",
        "            color: red;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>h1 태그</h1>\n",
        "    <h2 id=\"target1\">h2 태그</h2>\n",
        "    <h3>h3 태그</h3>\n",
        "    <a href=\"/\" id=\"target2\">a 태그</a>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "soup4 = BeautifulSoup(html,'html.parser')\n",
        "t1 = soup4.head.title\n",
        "h2 = soup4.find('h2', id='target1')\n",
        "a = soup4.find_all('a')\n",
        "\n",
        "print(t1)\n",
        "print(h2)\n",
        "print(a)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFoGFklxecb1"
      },
      "source": [
        "# Q. 아래 html 문에서 다음과 같이 출력되도록 스크레이핑 하세요.\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html = \"\"\"\n",
        "<html><body>\n",
        "<div id=\"meigen\">\n",
        "  <h1>HTML 기본 구조</h1>\n",
        "  <ul class=\"items\">\n",
        "    <li>html5 명시</li>\n",
        "    <li>html 태그로 모든 태그를 감싸줌. lang이란 속성을 포함</li>\n",
        "    <li>head 태그는 meta, title 이외의 style, script, link와 같은 태그 포함</li>\n",
        "    <li>title 태그는 문서의 제목</li>\n",
        "    <li>body 태그는 웹페이지의 내용 포함</li>\n",
        "    <li>style 태그는 CSS 코드가 포함된는 태그</li>\n",
        "    <li>script 태그는 JavaScript 코드를 작성하거나 파일 로드. head 태그 or body 태그 하단 위치</li>\n",
        "  </ul>\n",
        "</div>\n",
        "</body></html>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html,'html.parser')\n",
        "h1 = soup.h1.string\n",
        "print(\"h1 = \",h1)\n",
        "\n",
        "li_list = soup.select('div#meigen > ul.items > li')\n",
        "\n",
        "for li in li_list:\n",
        "    print(\"li = \", li.string)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1YI5tW-ecfI"
      },
      "source": [
        "h1 = HTML 기본 구조\n",
        "li = html5 명시\n",
        "li = html 태그로 모든 태그를 감싸줌. lang이란 속성을 포함\n",
        "li = head 태그는 meta, title 이외의 style, script, link와 같은 태그 포함\n",
        "li = title 태그는 문서의 제목\n",
        "li = body 태그는 웹페이지의 내용 포함\n",
        "li = style 태그는 CSS 코드가 포함된는 태그\n",
        "li = script 태그는 JavaScript 코드를 작성하거나 파일 로드. head 태그 or body 태그 하단 위치"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9Ckn6wHeciQ"
      },
      "source": [
        "#특정 웹사이트를 지정해서 원하는 크롤링 만들기 (최대한 역량 발휘)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfCtSpwreclX"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "req = requests.get('https://www.billboard-japan.com/charts/detail?a=hot100')\n",
        "html = req.text\n",
        "\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "rank = soup.select('#rank10 > td.rank_td.pc_obj > span:nth-child(1)')\n",
        "\n",
        "song = soup.select('#rank10 > td.name_td > div.name_detail > p.musuc_title')\n",
        "\n",
        "artist = soup.select('#rank10 > td.name_td > div.name_detail > p.artist_name')\n",
        "\n",
        "music_chart = []\n",
        "for item in zip(rank,song,artist):\n",
        "    music_chart.append(\n",
        "    {\n",
        "        'rank' : item[0].text,\n",
        "        'song' : item[1].text,\n",
        "        'artist' : item[2].text,\n",
        "    }\n",
        "    )\n",
        "    \n",
        "for i in music_chart:\n",
        "    print(i)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgk944Y-eco0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp95rfTvecr7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wypE-5b7ecvK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZfMErGtecyS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDIm2JDXec15"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtTCtluxec5N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbbRocIeec8T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjMge8LGec_j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkT4GfyhedC4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxXfChUcedGE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyWQZyAtedJV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMKpDAl2edM0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNUwapaGedP9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o0XnZS1edTP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}